{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK2gE4IYpFqu",
        "outputId": "87355aac-2c1e-4e11-f2c1-203173abda08"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#metrics"
      ],
      "metadata": {
        "id": "eKetU_kznosl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "OOyT5H-zmq5-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return dice_loss(y_true, y_pred) + tf.keras.losses.binary_crossentropy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Se"
      ],
      "metadata": {
        "id": "PM9XDaRgoCQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape, Dense, Multiply, Add, Permute, Conv2D\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "\n",
        "def squeeze_excite_block(input, ratio=16):\n",
        "    ''' Create a channel-wise squeeze-excite block\n",
        "\n",
        "    Args:\n",
        "        input: input tensor\n",
        "        filters: number of output filters\n",
        "\n",
        "    Returns: a keras tensor\n",
        "\n",
        "    References\n",
        "    -   [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
        "    '''\n",
        "    init = input\n",
        "    filters = init.shape[-1]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    x = Multiply()([init, se])\n",
        "    return x\n",
        "\n",
        "\n",
        "def spatial_squeeze_excite_block(input):\n",
        "    ''' Create a spatial squeeze-excite block\n",
        "\n",
        "    Args:\n",
        "        input: input tensor\n",
        "\n",
        "    Returns: a keras tensor\n",
        "\n",
        "    References\n",
        "    -   [Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks](https://arxiv.org/abs/1803.02579)\n",
        "    '''\n",
        "\n",
        "    se = Conv2D(1, (1, 1), activation='sigmoid', use_bias=False,\n",
        "                kernel_initializer='he_normal')(input)\n",
        "\n",
        "    x = multiply([input, se])\n",
        "    return x\n",
        "\n",
        "\n",
        "def channel_spatial_squeeze_excite(input, ratio=16):\n",
        "    ''' Create a spatial squeeze-excite block\n",
        "\n",
        "    Args:\n",
        "        input: input tensor\n",
        "        filters: number of output filters\n",
        "\n",
        "    Returns: a keras tensor\n",
        "\n",
        "    References\n",
        "    -   [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)\n",
        "    -   [Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks](https://arxiv.org/abs/1803.02579)\n",
        "    '''\n",
        "\n",
        "    cse = squeeze_excite_block(input, ratio)\n",
        "    sse = spatial_squeeze_excite_block(input)\n",
        "\n",
        "    x = Add([cse, sse])\n",
        "    return x"
      ],
      "metadata": {
        "id": "csdWOzRcoB5d"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model"
      ],
      "metadata": {
        "id": "f1ZIULAUm6TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.layers import Reshape\n",
        "os.environ['SSL_CERT_DIR'] = '/etc/ssl/certs'\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "from keras.applications import MobileNetV2\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, Multiply, Add, BatchNormalization, Activation\n",
        "from keras.layers import Cropping2D,UpSampling2D, Input, Concatenate\n",
        "from keras.layers import Dropout\n",
        "from keras.regularizers import l2\n",
        "\n",
        "def residual_block(x, num_filters):\n",
        "    x_init = x\n",
        "    x = Conv2D(num_filters//4, (1, 1), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters//4, (3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    s = Conv2D(num_filters, (1, 1), padding=\"same\")(x_init)\n",
        "    s = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, s])\n",
        "    x = Activation(\"relu\")(x)\n",
        "    x = squeeze_excite_block(x)\n",
        "    return x\n",
        "\n",
        "def NanoNet_A(input_shape):\n",
        "\n",
        "    f = [32, 64, 128]\n",
        "    inputs = Input(shape=input_shape, name=\"input_image\")\n",
        "\n",
        "    ## Encoder\n",
        "    encoder = MobileNetV2(input_tensor=inputs, weights=\"imagenet\", include_top=False, alpha=0.50)\n",
        "    encoder_output = encoder.get_layer(name=\"block_6_expand_relu\").output\n",
        "    skip_connections_name = [\"input_image\", \"block_1_expand_relu\", \"block_3_expand_relu\"]\n",
        "\n",
        "    x = residual_block(encoder_output, 192)\n",
        "\n",
        "    ## Decoder\n",
        "    for i in range(1, len(skip_connections_name)+1, 1):\n",
        "        x_skip = encoder.get_layer(skip_connections_name[-i]).output\n",
        "        x_skip = Conv2D(f[-i], (1, 1), padding=\"same\")(x_skip)\n",
        "        x_skip = BatchNormalization()(x_skip)\n",
        "        x_skip = Activation(\"relu\")(x_skip)\n",
        "\n",
        "        x = UpSampling2D((2, 2), interpolation='bilinear')(x)\n",
        "\n",
        "        try:\n",
        "            x = Concatenate()([x, x_skip])\n",
        "        except Exception as e:\n",
        "            x = Cropping2D(cropping=((1, 0), (0, 0)))(x)\n",
        "            x = Concatenate()([x, x_skip])\n",
        "\n",
        "        x = residual_block(x, f[-i])\n",
        "\n",
        "    ## Output\n",
        "    x = Conv2D(1, (1, 1), padding=\"same\")(x)\n",
        "    x = Activation(\"sigmoid\")(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    params = {\"img_height\": 256, \"img_width\": 256, \"img_channels\": 3, \"mask_channels\": 1}\n",
        "    input_shape = (params[\"img_height\"], params[\"img_width\"], params[\"img_channels\"])\n",
        "    model = NanoNet_A(input_shape)\n",
        "    model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhyi9W__ngsl",
        "outputId": "b6030f6c-9584-4089-f219-81023a71657b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_image (InputLayer)    [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (None, 128, 128, 16)         432       ['input_image[0][0]']         \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalizati  (None, 128, 128, 16)         64        ['Conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)           (None, 128, 128, 16)         0         ['bn_Conv1[0][0]']            \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (D  (None, 128, 128, 16)         144       ['Conv1_relu[0][0]']          \n",
            " epthwiseConv2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN  (None, 128, 128, 16)         64        ['expanded_conv_depthwise[0][0\n",
            "  (BatchNormalization)                                              ]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_re  (None, 128, 128, 16)         0         ['expanded_conv_depthwise_BN[0\n",
            " lu (ReLU)                                                          ][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_project (Con  (None, 128, 128, 8)          128       ['expanded_conv_depthwise_relu\n",
            " v2D)                                                               [0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (  (None, 128, 128, 8)          32        ['expanded_conv_project[0][0]'\n",
            " BatchNormalization)                                                ]                             \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)     (None, 128, 128, 48)         384       ['expanded_conv_project_BN[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNo  (None, 128, 128, 48)         192       ['block_1_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)  (None, 128, 128, 48)         0         ['block_1_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D  (None, 129, 129, 48)         0         ['block_1_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_1_depthwise (Depthwi  (None, 64, 64, 48)           432       ['block_1_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (Batc  (None, 64, 64, 48)           192       ['block_1_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (Re  (None, 64, 64, 48)           0         ['block_1_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)    (None, 64, 64, 16)           768       ['block_1_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchN  (None, 64, 64, 16)           64        ['block_1_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)     (None, 64, 64, 96)           1536      ['block_1_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNo  (None, 64, 64, 96)           384       ['block_2_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)  (None, 64, 64, 96)           0         ['block_2_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_depthwise (Depthwi  (None, 64, 64, 96)           864       ['block_2_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (Batc  (None, 64, 64, 96)           384       ['block_2_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (Re  (None, 64, 64, 96)           0         ['block_2_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)    (None, 64, 64, 16)           1536      ['block_2_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchN  (None, 64, 64, 16)           64        ['block_2_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_add (Add)           (None, 64, 64, 16)           0         ['block_1_project_BN[0][0]',  \n",
            "                                                                     'block_2_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)     (None, 64, 64, 96)           1536      ['block_2_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNo  (None, 64, 64, 96)           384       ['block_3_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)  (None, 64, 64, 96)           0         ['block_3_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D  (None, 65, 65, 96)           0         ['block_3_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_3_depthwise (Depthwi  (None, 32, 32, 96)           864       ['block_3_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (Batc  (None, 32, 32, 96)           384       ['block_3_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (Re  (None, 32, 32, 96)           0         ['block_3_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)    (None, 32, 32, 16)           1536      ['block_3_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchN  (None, 32, 32, 16)           64        ['block_3_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)     (None, 32, 32, 96)           1536      ['block_3_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNo  (None, 32, 32, 96)           384       ['block_4_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)  (None, 32, 32, 96)           0         ['block_4_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_depthwise (Depthwi  (None, 32, 32, 96)           864       ['block_4_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (Batc  (None, 32, 32, 96)           384       ['block_4_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (Re  (None, 32, 32, 96)           0         ['block_4_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)    (None, 32, 32, 16)           1536      ['block_4_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchN  (None, 32, 32, 16)           64        ['block_4_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_add (Add)           (None, 32, 32, 16)           0         ['block_3_project_BN[0][0]',  \n",
            "                                                                     'block_4_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)     (None, 32, 32, 96)           1536      ['block_4_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNo  (None, 32, 32, 96)           384       ['block_5_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)  (None, 32, 32, 96)           0         ['block_5_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_depthwise (Depthwi  (None, 32, 32, 96)           864       ['block_5_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (Batc  (None, 32, 32, 96)           384       ['block_5_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (Re  (None, 32, 32, 96)           0         ['block_5_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)    (None, 32, 32, 16)           1536      ['block_5_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchN  (None, 32, 32, 16)           64        ['block_5_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_5_add (Add)           (None, 32, 32, 16)           0         ['block_4_add[0][0]',         \n",
            "                                                                     'block_5_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)     (None, 32, 32, 96)           1536      ['block_5_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNo  (None, 32, 32, 96)           384       ['block_6_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)  (None, 32, 32, 96)           0         ['block_6_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_140 (Conv2D)         (None, 32, 32, 48)           4656      ['block_6_expand_relu[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_133 (B  (None, 32, 32, 48)           192       ['conv2d_140[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_112 (Activation  (None, 32, 32, 48)           0         ['batch_normalization_133[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_141 (Conv2D)         (None, 32, 32, 48)           20784     ['activation_112[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_134 (B  (None, 32, 32, 48)           192       ['conv2d_141[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_113 (Activation  (None, 32, 32, 48)           0         ['batch_normalization_134[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_142 (Conv2D)         (None, 32, 32, 192)          83136     ['activation_113[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_135 (B  (None, 32, 32, 192)          768       ['conv2d_142[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_136 (B  (None, 32, 32, 192)          768       ['batch_normalization_135[0][0\n",
            " atchNormalization)                                                 ]']                           \n",
            "                                                                                                  \n",
            " add_28 (Add)                (None, 32, 32, 192)          0         ['batch_normalization_135[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_136[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_114 (Activation  (None, 32, 32, 192)          0         ['add_28[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 192)                  0         ['activation_114[0][0]']      \n",
            " 8 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_28 (Reshape)        (None, 1, 1, 192)            0         ['global_average_pooling2d_28[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_56 (Dense)            (None, 1, 1, 12)             2304      ['reshape_28[0][0]']          \n",
            "                                                                                                  \n",
            " dense_57 (Dense)            (None, 1, 1, 192)            2304      ['dense_56[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_144 (Conv2D)         (None, 64, 64, 128)          12416     ['block_3_expand_relu[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_28 (Multiply)      (None, 32, 32, 192)          0         ['activation_114[0][0]',      \n",
            "                                                                     'dense_57[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_137 (B  (None, 64, 64, 128)          512       ['conv2d_144[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " up_sampling2d_21 (UpSampli  (None, 64, 64, 192)          0         ['multiply_28[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " activation_115 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_137[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " concatenate_21 (Concatenat  (None, 64, 64, 320)          0         ['up_sampling2d_21[0][0]',    \n",
            " e)                                                                  'activation_115[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_145 (Conv2D)         (None, 64, 64, 32)           10272     ['concatenate_21[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_138 (B  (None, 64, 64, 32)           128       ['conv2d_145[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_116 (Activation  (None, 64, 64, 32)           0         ['batch_normalization_138[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_146 (Conv2D)         (None, 64, 64, 32)           9248      ['activation_116[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_139 (B  (None, 64, 64, 32)           128       ['conv2d_146[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_117 (Activation  (None, 64, 64, 32)           0         ['batch_normalization_139[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_147 (Conv2D)         (None, 64, 64, 128)          36992     ['activation_117[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_140 (B  (None, 64, 64, 128)          512       ['conv2d_147[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_141 (B  (None, 64, 64, 128)          512       ['batch_normalization_140[0][0\n",
            " atchNormalization)                                                 ]']                           \n",
            "                                                                                                  \n",
            " add_29 (Add)                (None, 64, 64, 128)          0         ['batch_normalization_140[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_141[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_118 (Activation  (None, 64, 64, 128)          0         ['add_29[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_2  (None, 128)                  0         ['activation_118[0][0]']      \n",
            " 9 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_29 (Reshape)        (None, 1, 1, 128)            0         ['global_average_pooling2d_29[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_58 (Dense)            (None, 1, 1, 8)              1024      ['reshape_29[0][0]']          \n",
            "                                                                                                  \n",
            " dense_59 (Dense)            (None, 1, 1, 128)            1024      ['dense_58[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_149 (Conv2D)         (None, 128, 128, 64)         3136      ['block_1_expand_relu[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_29 (Multiply)      (None, 64, 64, 128)          0         ['activation_118[0][0]',      \n",
            "                                                                     'dense_59[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_142 (B  (None, 128, 128, 64)         256       ['conv2d_149[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " up_sampling2d_22 (UpSampli  (None, 128, 128, 128)        0         ['multiply_29[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " activation_119 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_142[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " concatenate_22 (Concatenat  (None, 128, 128, 192)        0         ['up_sampling2d_22[0][0]',    \n",
            " e)                                                                  'activation_119[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_150 (Conv2D)         (None, 128, 128, 16)         3088      ['concatenate_22[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_143 (B  (None, 128, 128, 16)         64        ['conv2d_150[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_120 (Activation  (None, 128, 128, 16)         0         ['batch_normalization_143[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_151 (Conv2D)         (None, 128, 128, 16)         2320      ['activation_120[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_144 (B  (None, 128, 128, 16)         64        ['conv2d_151[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_121 (Activation  (None, 128, 128, 16)         0         ['batch_normalization_144[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_152 (Conv2D)         (None, 128, 128, 64)         9280      ['activation_121[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_145 (B  (None, 128, 128, 64)         256       ['conv2d_152[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_146 (B  (None, 128, 128, 64)         256       ['batch_normalization_145[0][0\n",
            " atchNormalization)                                                 ]']                           \n",
            "                                                                                                  \n",
            " add_30 (Add)                (None, 128, 128, 64)         0         ['batch_normalization_145[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_146[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_122 (Activation  (None, 128, 128, 64)         0         ['add_30[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 64)                   0         ['activation_122[0][0]']      \n",
            " 0 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_30 (Reshape)        (None, 1, 1, 64)             0         ['global_average_pooling2d_30[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_60 (Dense)            (None, 1, 1, 4)              256       ['reshape_30[0][0]']          \n",
            "                                                                                                  \n",
            " dense_61 (Dense)            (None, 1, 1, 64)             256       ['dense_60[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_154 (Conv2D)         (None, 256, 256, 32)         128       ['input_image[0][0]']         \n",
            "                                                                                                  \n",
            " multiply_30 (Multiply)      (None, 128, 128, 64)         0         ['activation_122[0][0]',      \n",
            "                                                                     'dense_61[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_147 (B  (None, 256, 256, 32)         128       ['conv2d_154[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " up_sampling2d_23 (UpSampli  (None, 256, 256, 64)         0         ['multiply_30[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " activation_123 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_147[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " concatenate_23 (Concatenat  (None, 256, 256, 96)         0         ['up_sampling2d_23[0][0]',    \n",
            " e)                                                                  'activation_123[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_155 (Conv2D)         (None, 256, 256, 8)          776       ['concatenate_23[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_148 (B  (None, 256, 256, 8)          32        ['conv2d_155[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_124 (Activation  (None, 256, 256, 8)          0         ['batch_normalization_148[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_156 (Conv2D)         (None, 256, 256, 8)          584       ['activation_124[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_149 (B  (None, 256, 256, 8)          32        ['conv2d_156[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_125 (Activation  (None, 256, 256, 8)          0         ['batch_normalization_149[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_157 (Conv2D)         (None, 256, 256, 32)         2336      ['activation_125[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_150 (B  (None, 256, 256, 32)         128       ['conv2d_157[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_151 (B  (None, 256, 256, 32)         128       ['batch_normalization_150[0][0\n",
            " atchNormalization)                                                 ]']                           \n",
            "                                                                                                  \n",
            " add_31 (Add)                (None, 256, 256, 32)         0         ['batch_normalization_150[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_151[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_126 (Activation  (None, 256, 256, 32)         0         ['add_31[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 32)                   0         ['activation_126[0][0]']      \n",
            " 1 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_31 (Reshape)        (None, 1, 1, 32)             0         ['global_average_pooling2d_31[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_62 (Dense)            (None, 1, 1, 2)              64        ['reshape_31[0][0]']          \n",
            "                                                                                                  \n",
            " dense_63 (Dense)            (None, 1, 1, 32)             64        ['dense_62[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_31 (Multiply)      (None, 256, 256, 32)         0         ['activation_126[0][0]',      \n",
            "                                                                     'dense_63[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_159 (Conv2D)         (None, 256, 256, 1)          33        ['multiply_31[0][0]']         \n",
            "                                                                                                  \n",
            " activation_127 (Activation  (None, 256, 256, 1)          0         ['conv2d_159[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 235425 (919.63 KB)\n",
            "Trainable params: 230737 (901.32 KB)\n",
            "Non-trainable params: 4688 (18.31 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "yaVq7EoOvQFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from dimensionality_reduction import apply_pca_to_image,reduce_mask_dimension,save_image\n",
        "\n",
        "H = 256\n",
        "W = 256\n",
        "\n",
        "def load_names(path, file_path):\n",
        "    f = open(file_path, \"r\")\n",
        "    data = f.read().split(\"\\n\")[:-1]\n",
        "    images = [os.path.join(path, \"images\", name) + \".jpg\" for name in data]\n",
        "    masks = [os.path.join(path, \"masks\", name) + \".jpg\" for name in data]\n",
        "    return images, masks\n",
        "\n",
        "def load_data(path):\n",
        "    train_names_path = f\"{path}/train.txt\"\n",
        "    valid_names_path = f\"{path}/val.txt\"\n",
        "\n",
        "    train_x, train_y = load_names(path, train_names_path)\n",
        "    valid_x, valid_y = load_names(path, valid_names_path)\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y)\n",
        "\n",
        "def load_test_data(path):\n",
        "    train_names_path = f\"{path}/train.txt\"\n",
        "    test_names_path = f\"{path}/test.txt\"\n",
        "\n",
        "    train_x, train_y = load_names(path, train_names_path)\n",
        "    test_x, test_y = load_names(path, test_names_path)\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "def read_image(path):\n",
        "\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x/255.0\n",
        "    x = np.expand_dims(x, axis=-1)\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
        "    x.set_shape([H, W, 3])\n",
        "    y.set_shape([H, W, 1])\n",
        "    return x, y\n",
        "\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "IYnZY6mivWl3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "OHOMge78ve6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, List\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "from keras.utils import CustomObjectScope\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import load_model\n",
        "from keras.utils import custom_object_scope\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def create_dir(path):\n",
        "    \"\"\" Create a directory. \"\"\"\n",
        "    try:\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "    except OSError:\n",
        "        print(f\"Error: creating directory with name {path}\")\n",
        "\n",
        "def shuffling(x, y):\n",
        "    x, y = shuffle(x, y, random_state=42)\n",
        "    return x, y\n",
        "\n",
        "def load_model_file(path):\n",
        "    with CustomObjectScope({\n",
        "            'iou':iou,\n",
        "            'dice_coef':dice_coef,\n",
        "            'dice_loss':dice_loss,\n",
        "            'bce_dice_loss': bce_dice_loss\n",
        "        }):\n",
        "        model = tf.keras.models.load_model(path)\n",
        "        return model"
      ],
      "metadata": {
        "id": "FkXytfLvvkPW"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sgdr\n"
      ],
      "metadata": {
        "id": "URswsGAAv4pO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "class SGDRScheduler(Callback):\n",
        "\n",
        "    def __init__(self,\n",
        "                 min_lr,\n",
        "                 max_lr,\n",
        "                 steps_per_epoch,\n",
        "                 lr_decay=1,\n",
        "                 cycle_length=10,\n",
        "                 mult_factor=2):\n",
        "\n",
        "        self.min_lr = min_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.lr_decay = lr_decay\n",
        "\n",
        "        self.batch_since_restart = 0\n",
        "        self.next_restart = cycle_length\n",
        "\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "\n",
        "        self.cycle_length = cycle_length\n",
        "        self.mult_factor = mult_factor\n",
        "\n",
        "        self.history = {}\n",
        "\n",
        "    def clr(self):\n",
        "        '''Calculate the learning rate.'''\n",
        "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
        "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
        "        return lr\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
        "        logs = logs or {}\n",
        "        K.set_value(self.model.optimizer.lr, self.max_lr)\n",
        "\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        '''Record previous batch statistics and update the learning rate.'''\n",
        "        logs = logs or {}\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "\n",
        "        self.batch_since_restart += 1\n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
        "        if epoch + 1 == self.next_restart:\n",
        "            self.batch_since_restart = 0\n",
        "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
        "            self.next_restart += self.cycle_length\n",
        "            self.max_lr *= self.lr_decay\n",
        "            self.best_weights = self.model.get_weights()\n",
        "\n",
        "    def on_train_end(self, logs={}):\n",
        "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
        "        self.model.set_weights(self.best_weights)\n"
      ],
      "metadata": {
        "id": "DFBfW-Gev7Lo"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train"
      ],
      "metadata": {
        "id": "4DLQuj1MvtK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from keras.metrics import Recall, Precision, MeanIoU\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "    \"\"\" Remove folders and files \"\"\"\n",
        "    # os.system(\"rm files/files.csv\")\n",
        "    # os.system(\"rm -r logs\")\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    input_shape = (256, 256, 3)\n",
        "    batch_size = 8\n",
        "    lr = 1e-4\n",
        "    epochs = 200\n",
        "    model_name = \"NanoNet_A\"\n",
        "    model_path = f\"files/{model_name}/model.h5\"\n",
        "    csv_path = f\"files/{model_name}/model.csv\"\n",
        "    log_path = f\"logs/{model_name}/\"\n",
        "    \"\"\" Creating folders \"\"\"\n",
        "    create_dir(f\"files/{model_name}\")\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    path = '/content/drive/MyDrive/capstone/Kvasir-SEG'\n",
        "\n",
        "    (train_x, train_y), (valid_x, valid_y) = load_data(path)\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch_size)\n",
        "\n",
        "    # \"\"\" Model \"\"\"\n",
        "    model = NanoNet_A(input_shape)\n",
        "\n",
        "    metrics = [dice_coef, iou, Recall(), Precision()]\n",
        "    model.compile(loss=bce_dice_loss, optimizer=Adam(lr), metrics=metrics)\n",
        "    model.summary()\n",
        "\n",
        "    #\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-7, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        TensorBoard(log_dir=log_path),\n",
        "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
        "    ]\n",
        "\n",
        "    train_steps = (len(train_x)//batch_size)\n",
        "    valid_steps = (len(valid_x)//batch_size)\n",
        "\n",
        "    if len(train_x) % batch_size != 0:\n",
        "        train_steps += 1\n",
        "\n",
        "    if len(valid_x) % batch_size != 0:\n",
        "        valid_steps += 1\n",
        "\n",
        "    model.fit(train_dataset,\n",
        "            epochs=epochs,\n",
        "            validation_data=valid_dataset,\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_steps=valid_steps,\n",
        "            callbacks=callbacks,\n",
        "            shuffle= False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ejrVNs_vzm6",
        "outputId": "4fca4c97-3d0b-4639-da8e-d0e533b30525"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_image (InputLayer)    [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (None, 128, 128, 16)         432       ['input_image[0][0]']         \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalizati  (None, 128, 128, 16)         64        ['Conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)           (None, 128, 128, 16)         0         ['bn_Conv1[0][0]']            \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (D  (None, 128, 128, 16)         144       ['Conv1_relu[0][0]']          \n",
            " epthwiseConv2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN  (None, 128, 128, 16)         64        ['expanded_conv_depthwise[0][0\n",
            "  (BatchNormalization)                                              ]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_re  (None, 128, 128, 16)         0         ['expanded_conv_depthwise_BN[0\n",
            " lu (ReLU)                                                          ][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_project (Con  (None, 128, 128, 8)          128       ['expanded_conv_depthwise_relu\n",
            " v2D)                                                               [0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (  (None, 128, 128, 8)          32        ['expanded_conv_project[0][0]'\n",
            " BatchNormalization)                                                ]                             \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)     (None, 128, 128, 48)         384       ['expanded_conv_project_BN[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNo  (None, 128, 128, 48)         192       ['block_1_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)  (None, 128, 128, 48)         0         ['block_1_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D  (None, 129, 129, 48)         0         ['block_1_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_1_depthwise (Depthwi  (None, 64, 64, 48)           432       ['block_1_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (Batc  (None, 64, 64, 48)           192       ['block_1_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (Re  (None, 64, 64, 48)           0         ['block_1_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)    (None, 64, 64, 16)           768       ['block_1_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchN  (None, 64, 64, 16)           64        ['block_1_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)     (None, 64, 64, 96)           1536      ['block_1_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNo  (None, 64, 64, 96)           384       ['block_2_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)  (None, 64, 64, 96)           0         ['block_2_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_depthwise (Depthwi  (None, 64, 64, 96)           864       ['block_2_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (Batc  (None, 64, 64, 96)           384       ['block_2_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (Re  (None, 64, 64, 96)           0         ['block_2_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)    (None, 64, 64, 16)           1536      ['block_2_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchN  (None, 64, 64, 16)           64        ['block_2_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_add (Add)           (None, 64, 64, 16)           0         ['block_1_project_BN[0][0]',  \n",
            "                                                                     'block_2_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)     (None, 64, 64, 96)           1536      ['block_2_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNo  (None, 64, 64, 96)           384       ['block_3_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)  (None, 64, 64, 96)           0         ['block_3_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D  (None, 65, 65, 96)           0         ['block_3_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_3_depthwise (Depthwi  (None, 32, 32, 96)           864       ['block_3_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (Batc  (None, 32, 32, 96)           384       ['block_3_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (Re  (None, 32, 32, 96)           0         ['block_3_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)    (None, 32, 32, 16)           1536      ['block_3_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchN  (None, 32, 32, 16)           64        ['block_3_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)     (None, 32, 32, 96)           1536      ['block_3_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNo  (None, 32, 32, 96)           384       ['block_4_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)  (None, 32, 32, 96)           0         ['block_4_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_depthwise (Depthwi  (None, 32, 32, 96)           864       ['block_4_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (Batc  (None, 32, 32, 96)           384       ['block_4_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (Re  (None, 32, 32, 96)           0         ['block_4_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)    (None, 32, 32, 16)           1536      ['block_4_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchN  (None, 32, 32, 16)           64        ['block_4_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_add (Add)           (None, 32, 32, 16)           0         ['block_3_project_BN[0][0]',  \n",
            "                                                                     'block_4_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)     (None, 32, 32, 96)           1536      ['block_4_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNo  (None, 32, 32, 96)           384       ['block_5_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)  (None, 32, 32, 96)           0         ['block_5_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_depthwise (Depthwi  (None, 32, 32, 96)           864       ['block_5_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (Batc  (None, 32, 32, 96)           384       ['block_5_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (Re  (None, 32, 32, 96)           0         ['block_5_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)    (None, 32, 32, 16)           1536      ['block_5_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchN  (None, 32, 32, 16)           64        ['block_5_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_5_add (Add)           (None, 32, 32, 16)           0         ['block_4_add[0][0]',         \n",
            "                                                                     'block_5_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)     (None, 32, 32, 96)           1536      ['block_5_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNo  (None, 32, 32, 96)           384       ['block_6_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)  (None, 32, 32, 96)           0         ['block_6_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " conv2d_160 (Conv2D)         (None, 32, 32, 48)           4656      ['block_6_expand_relu[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_152 (B  (None, 32, 32, 48)           192       ['conv2d_160[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_128 (Activation  (None, 32, 32, 48)           0         ['batch_normalization_152[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_161 (Conv2D)         (None, 32, 32, 48)           20784     ['activation_128[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_153 (B  (None, 32, 32, 48)           192       ['conv2d_161[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_129 (Activation  (None, 32, 32, 48)           0         ['batch_normalization_153[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_162 (Conv2D)         (None, 32, 32, 192)          83136     ['activation_129[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_154 (B  (None, 32, 32, 192)          768       ['conv2d_162[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_155 (B  (None, 32, 32, 192)          768       ['batch_normalization_154[0][0\n",
            " atchNormalization)                                                 ]']                           \n",
            "                                                                                                  \n",
            " add_32 (Add)                (None, 32, 32, 192)          0         ['batch_normalization_154[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_155[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_130 (Activation  (None, 32, 32, 192)          0         ['add_32[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 192)                  0         ['activation_130[0][0]']      \n",
            " 2 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_32 (Reshape)        (None, 1, 1, 192)            0         ['global_average_pooling2d_32[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_64 (Dense)            (None, 1, 1, 12)             2304      ['reshape_32[0][0]']          \n",
            "                                                                                                  \n",
            " dense_65 (Dense)            (None, 1, 1, 192)            2304      ['dense_64[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_164 (Conv2D)         (None, 64, 64, 128)          12416     ['block_3_expand_relu[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_32 (Multiply)      (None, 32, 32, 192)          0         ['activation_130[0][0]',      \n",
            "                                                                     'dense_65[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_156 (B  (None, 64, 64, 128)          512       ['conv2d_164[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " up_sampling2d_24 (UpSampli  (None, 64, 64, 192)          0         ['multiply_32[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " activation_131 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_156[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " concatenate_24 (Concatenat  (None, 64, 64, 320)          0         ['up_sampling2d_24[0][0]',    \n",
            " e)                                                                  'activation_131[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_165 (Conv2D)         (None, 64, 64, 32)           10272     ['concatenate_24[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_157 (B  (None, 64, 64, 32)           128       ['conv2d_165[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_132 (Activation  (None, 64, 64, 32)           0         ['batch_normalization_157[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_166 (Conv2D)         (None, 64, 64, 32)           9248      ['activation_132[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_158 (B  (None, 64, 64, 32)           128       ['conv2d_166[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_133 (Activation  (None, 64, 64, 32)           0         ['batch_normalization_158[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_167 (Conv2D)         (None, 64, 64, 128)          36992     ['activation_133[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_159 (B  (None, 64, 64, 128)          512       ['conv2d_167[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_160 (B  (None, 64, 64, 128)          512       ['batch_normalization_159[0][0\n",
            " atchNormalization)                                                 ]']                           \n",
            "                                                                                                  \n",
            " add_33 (Add)                (None, 64, 64, 128)          0         ['batch_normalization_159[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_160[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_134 (Activation  (None, 64, 64, 128)          0         ['add_33[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 128)                  0         ['activation_134[0][0]']      \n",
            " 3 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_33 (Reshape)        (None, 1, 1, 128)            0         ['global_average_pooling2d_33[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_66 (Dense)            (None, 1, 1, 8)              1024      ['reshape_33[0][0]']          \n",
            "                                                                                                  \n",
            " dense_67 (Dense)            (None, 1, 1, 128)            1024      ['dense_66[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_169 (Conv2D)         (None, 128, 128, 64)         3136      ['block_1_expand_relu[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_33 (Multiply)      (None, 64, 64, 128)          0         ['activation_134[0][0]',      \n",
            "                                                                     'dense_67[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_161 (B  (None, 128, 128, 64)         256       ['conv2d_169[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " up_sampling2d_25 (UpSampli  (None, 128, 128, 128)        0         ['multiply_33[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " activation_135 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_161[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " concatenate_25 (Concatenat  (None, 128, 128, 192)        0         ['up_sampling2d_25[0][0]',    \n",
            " e)                                                                  'activation_135[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_170 (Conv2D)         (None, 128, 128, 16)         3088      ['concatenate_25[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_162 (B  (None, 128, 128, 16)         64        ['conv2d_170[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_136 (Activation  (None, 128, 128, 16)         0         ['batch_normalization_162[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_171 (Conv2D)         (None, 128, 128, 16)         2320      ['activation_136[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_163 (B  (None, 128, 128, 16)         64        ['conv2d_171[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_137 (Activation  (None, 128, 128, 16)         0         ['batch_normalization_163[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_172 (Conv2D)         (None, 128, 128, 64)         9280      ['activation_137[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_164 (B  (None, 128, 128, 64)         256       ['conv2d_172[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_165 (B  (None, 128, 128, 64)         256       ['batch_normalization_164[0][0\n",
            " atchNormalization)                                                 ]']                           \n",
            "                                                                                                  \n",
            " add_34 (Add)                (None, 128, 128, 64)         0         ['batch_normalization_164[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_165[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_138 (Activation  (None, 128, 128, 64)         0         ['add_34[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 64)                   0         ['activation_138[0][0]']      \n",
            " 4 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_34 (Reshape)        (None, 1, 1, 64)             0         ['global_average_pooling2d_34[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_68 (Dense)            (None, 1, 1, 4)              256       ['reshape_34[0][0]']          \n",
            "                                                                                                  \n",
            " dense_69 (Dense)            (None, 1, 1, 64)             256       ['dense_68[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_174 (Conv2D)         (None, 256, 256, 32)         128       ['input_image[0][0]']         \n",
            "                                                                                                  \n",
            " multiply_34 (Multiply)      (None, 128, 128, 64)         0         ['activation_138[0][0]',      \n",
            "                                                                     'dense_69[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_166 (B  (None, 256, 256, 32)         128       ['conv2d_174[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " up_sampling2d_26 (UpSampli  (None, 256, 256, 64)         0         ['multiply_34[0][0]']         \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " activation_139 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_166[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " concatenate_26 (Concatenat  (None, 256, 256, 96)         0         ['up_sampling2d_26[0][0]',    \n",
            " e)                                                                  'activation_139[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_175 (Conv2D)         (None, 256, 256, 8)          776       ['concatenate_26[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_167 (B  (None, 256, 256, 8)          32        ['conv2d_175[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_140 (Activation  (None, 256, 256, 8)          0         ['batch_normalization_167[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)         (None, 256, 256, 8)          584       ['activation_140[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_168 (B  (None, 256, 256, 8)          32        ['conv2d_176[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_141 (Activation  (None, 256, 256, 8)          0         ['batch_normalization_168[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)         (None, 256, 256, 32)         2336      ['activation_141[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_169 (B  (None, 256, 256, 32)         128       ['conv2d_177[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_170 (B  (None, 256, 256, 32)         128       ['batch_normalization_169[0][0\n",
            " atchNormalization)                                                 ]']                           \n",
            "                                                                                                  \n",
            " add_35 (Add)                (None, 256, 256, 32)         0         ['batch_normalization_169[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'batch_normalization_170[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " activation_142 (Activation  (None, 256, 256, 32)         0         ['add_35[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3  (None, 32)                   0         ['activation_142[0][0]']      \n",
            " 5 (GlobalAveragePooling2D)                                                                       \n",
            "                                                                                                  \n",
            " reshape_35 (Reshape)        (None, 1, 1, 32)             0         ['global_average_pooling2d_35[\n",
            "                                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " dense_70 (Dense)            (None, 1, 1, 2)              64        ['reshape_35[0][0]']          \n",
            "                                                                                                  \n",
            " dense_71 (Dense)            (None, 1, 1, 32)             64        ['dense_70[0][0]']            \n",
            "                                                                                                  \n",
            " multiply_35 (Multiply)      (None, 256, 256, 32)         0         ['activation_142[0][0]',      \n",
            "                                                                     'dense_71[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_179 (Conv2D)         (None, 256, 256, 1)          33        ['multiply_35[0][0]']         \n",
            "                                                                                                  \n",
            " activation_143 (Activation  (None, 256, 256, 1)          0         ['conv2d_179[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 235425 (919.63 KB)\n",
            "Trainable params: 230737 (901.32 KB)\n",
            "Non-trainable params: 4688 (18.31 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.2783 - dice_coef: 0.3271 - iou: 0.1985 - recall_4: 0.6437 - precision_4: 0.3387\n",
            "Epoch 1: val_loss improved from inf to 1.34353, saving model to files/NanoNet_A/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r98/98 [==============================] - 43s 170ms/step - loss: 1.2783 - dice_coef: 0.3271 - iou: 0.1985 - recall_4: 0.6437 - precision_4: 0.3387 - val_loss: 1.3435 - val_dice_coef: 0.2176 - val_iou: 0.1236 - val_recall_4: 5.0699e-04 - val_precision_4: 0.4349 - lr: 1.0000e-04\n",
            "Epoch 2/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.9443 - dice_coef: 0.4435 - iou: 0.2880 - recall_4: 0.6852 - precision_4: 0.5637\n",
            "Epoch 2: val_loss improved from 1.34353 to 1.17629, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 15s 155ms/step - loss: 0.9443 - dice_coef: 0.4435 - iou: 0.2880 - recall_4: 0.6852 - precision_4: 0.5637 - val_loss: 1.1763 - val_dice_coef: 0.2462 - val_iou: 0.1414 - val_recall_4: 0.1645 - val_precision_4: 0.8344 - lr: 1.0000e-04\n",
            "Epoch 3/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.8070 - dice_coef: 0.5056 - iou: 0.3416 - recall_4: 0.7055 - precision_4: 0.6461\n",
            "Epoch 3: val_loss improved from 1.17629 to 1.05138, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 145ms/step - loss: 0.8070 - dice_coef: 0.5056 - iou: 0.3416 - recall_4: 0.7055 - precision_4: 0.6461 - val_loss: 1.0514 - val_dice_coef: 0.3046 - val_iou: 0.1807 - val_recall_4: 0.2662 - val_precision_4: 0.8272 - lr: 1.0000e-04\n",
            "Epoch 4/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.7239 - dice_coef: 0.5492 - iou: 0.3819 - recall_4: 0.7123 - precision_4: 0.7045\n",
            "Epoch 4: val_loss improved from 1.05138 to 0.94860, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 148ms/step - loss: 0.7239 - dice_coef: 0.5492 - iou: 0.3819 - recall_4: 0.7123 - precision_4: 0.7045 - val_loss: 0.9486 - val_dice_coef: 0.3750 - val_iou: 0.2321 - val_recall_4: 0.3671 - val_precision_4: 0.7899 - lr: 1.0000e-04\n",
            "Epoch 5/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.6608 - dice_coef: 0.5846 - iou: 0.4164 - recall_4: 0.7235 - precision_4: 0.7460\n",
            "Epoch 5: val_loss improved from 0.94860 to 0.89523, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 15s 152ms/step - loss: 0.6608 - dice_coef: 0.5846 - iou: 0.4164 - recall_4: 0.7235 - precision_4: 0.7460 - val_loss: 0.8952 - val_dice_coef: 0.4143 - val_iou: 0.2626 - val_recall_4: 0.3997 - val_precision_4: 0.7739 - lr: 1.0000e-04\n",
            "Epoch 6/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.6106 - dice_coef: 0.6139 - iou: 0.4464 - recall_4: 0.7372 - precision_4: 0.7755\n",
            "Epoch 6: val_loss improved from 0.89523 to 0.84981, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 13s 133ms/step - loss: 0.6106 - dice_coef: 0.6139 - iou: 0.4464 - recall_4: 0.7372 - precision_4: 0.7755 - val_loss: 0.8498 - val_dice_coef: 0.4502 - val_iou: 0.2921 - val_recall_4: 0.4277 - val_precision_4: 0.7668 - lr: 1.0000e-04\n",
            "Epoch 7/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5651 - dice_coef: 0.6417 - iou: 0.4759 - recall_4: 0.7531 - precision_4: 0.7996\n",
            "Epoch 7: val_loss improved from 0.84981 to 0.80269, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 145ms/step - loss: 0.5651 - dice_coef: 0.6417 - iou: 0.4759 - recall_4: 0.7531 - precision_4: 0.7996 - val_loss: 0.8027 - val_dice_coef: 0.4913 - val_iou: 0.3273 - val_recall_4: 0.4843 - val_precision_4: 0.7291 - lr: 1.0000e-04\n",
            "Epoch 8/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.5235 - dice_coef: 0.6678 - iou: 0.5047 - recall_4: 0.7670 - precision_4: 0.8210\n",
            "Epoch 8: val_loss improved from 0.80269 to 0.76380, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 13s 138ms/step - loss: 0.5235 - dice_coef: 0.6678 - iou: 0.5047 - recall_4: 0.7670 - precision_4: 0.8210 - val_loss: 0.7638 - val_dice_coef: 0.5313 - val_iou: 0.3639 - val_recall_4: 0.5605 - val_precision_4: 0.6823 - lr: 1.0000e-04\n",
            "Epoch 9/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4850 - dice_coef: 0.6925 - iou: 0.5330 - recall_4: 0.7805 - precision_4: 0.8399\n",
            "Epoch 9: val_loss improved from 0.76380 to 0.74778, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 15s 155ms/step - loss: 0.4850 - dice_coef: 0.6925 - iou: 0.5330 - recall_4: 0.7805 - precision_4: 0.8399 - val_loss: 0.7478 - val_dice_coef: 0.5572 - val_iou: 0.3889 - val_recall_4: 0.6166 - val_precision_4: 0.6519 - lr: 1.0000e-04\n",
            "Epoch 10/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4496 - dice_coef: 0.7156 - iou: 0.5604 - recall_4: 0.7928 - precision_4: 0.8574\n",
            "Epoch 10: val_loss did not improve from 0.74778\n",
            "98/98 [==============================] - 12s 123ms/step - loss: 0.4496 - dice_coef: 0.7156 - iou: 0.5604 - recall_4: 0.7928 - precision_4: 0.8574 - val_loss: 0.8260 - val_dice_coef: 0.5644 - val_iou: 0.3977 - val_recall_4: 0.7126 - val_precision_4: 0.5578 - lr: 1.0000e-04\n",
            "Epoch 11/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.4200 - dice_coef: 0.7355 - iou: 0.5847 - recall_4: 0.8019 - precision_4: 0.8712\n",
            "Epoch 11: val_loss did not improve from 0.74778\n",
            "98/98 [==============================] - 14s 141ms/step - loss: 0.4200 - dice_coef: 0.7355 - iou: 0.5847 - recall_4: 0.8019 - precision_4: 0.8712 - val_loss: 0.9636 - val_dice_coef: 0.5558 - val_iou: 0.3911 - val_recall_4: 0.7779 - val_precision_4: 0.4903 - lr: 1.0000e-04\n",
            "Epoch 12/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3919 - dice_coef: 0.7542 - iou: 0.6083 - recall_4: 0.8111 - precision_4: 0.8839\n",
            "Epoch 12: val_loss did not improve from 0.74778\n",
            "98/98 [==============================] - 13s 132ms/step - loss: 0.3919 - dice_coef: 0.7542 - iou: 0.6083 - recall_4: 0.8111 - precision_4: 0.8839 - val_loss: 1.1644 - val_dice_coef: 0.5345 - val_iou: 0.3719 - val_recall_4: 0.8205 - val_precision_4: 0.4361 - lr: 1.0000e-04\n",
            "Epoch 13/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3685 - dice_coef: 0.7702 - iou: 0.6290 - recall_4: 0.8181 - precision_4: 0.8943\n",
            "Epoch 13: val_loss did not improve from 0.74778\n",
            "98/98 [==============================] - 13s 133ms/step - loss: 0.3685 - dice_coef: 0.7702 - iou: 0.6290 - recall_4: 0.8181 - precision_4: 0.8943 - val_loss: 1.2455 - val_dice_coef: 0.5300 - val_iou: 0.3681 - val_recall_4: 0.8332 - val_precision_4: 0.4232 - lr: 1.0000e-04\n",
            "Epoch 14/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3507 - dice_coef: 0.7828 - iou: 0.6458 - recall_4: 0.8236 - precision_4: 0.8985\n",
            "Epoch 14: val_loss did not improve from 0.74778\n",
            "98/98 [==============================] - 13s 128ms/step - loss: 0.3507 - dice_coef: 0.7828 - iou: 0.6458 - recall_4: 0.8236 - precision_4: 0.8985 - val_loss: 1.3917 - val_dice_coef: 0.5166 - val_iou: 0.3572 - val_recall_4: 0.8463 - val_precision_4: 0.3976 - lr: 1.0000e-04\n",
            "Epoch 15/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3306 - dice_coef: 0.7955 - iou: 0.6630 - recall_4: 0.8297 - precision_4: 0.9080\n",
            "Epoch 15: val_loss did not improve from 0.74778\n",
            "98/98 [==============================] - 16s 160ms/step - loss: 0.3306 - dice_coef: 0.7955 - iou: 0.6630 - recall_4: 0.8297 - precision_4: 0.9080 - val_loss: 1.0633 - val_dice_coef: 0.5651 - val_iou: 0.4012 - val_recall_4: 0.8119 - val_precision_4: 0.4740 - lr: 1.0000e-04\n",
            "Epoch 16/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3127 - dice_coef: 0.8079 - iou: 0.6800 - recall_4: 0.8355 - precision_4: 0.9145\n",
            "Epoch 16: val_loss did not improve from 0.74778\n",
            "98/98 [==============================] - 13s 138ms/step - loss: 0.3127 - dice_coef: 0.8079 - iou: 0.6800 - recall_4: 0.8355 - precision_4: 0.9145 - val_loss: 0.8131 - val_dice_coef: 0.6151 - val_iou: 0.4488 - val_recall_4: 0.7493 - val_precision_4: 0.5810 - lr: 1.0000e-04\n",
            "Epoch 17/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.3070 - dice_coef: 0.8129 - iou: 0.6868 - recall_4: 0.8363 - precision_4: 0.9126\n",
            "Epoch 17: val_loss did not improve from 0.74778\n",
            "98/98 [==============================] - 13s 133ms/step - loss: 0.3070 - dice_coef: 0.8129 - iou: 0.6868 - recall_4: 0.8363 - precision_4: 0.9126 - val_loss: 0.7937 - val_dice_coef: 0.6199 - val_iou: 0.4558 - val_recall_4: 0.7770 - val_precision_4: 0.5732 - lr: 1.0000e-04\n",
            "Epoch 18/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2940 - dice_coef: 0.8212 - iou: 0.6988 - recall_4: 0.8407 - precision_4: 0.9163\n",
            "Epoch 18: val_loss did not improve from 0.74778\n",
            "98/98 [==============================] - 10s 104ms/step - loss: 0.2940 - dice_coef: 0.8212 - iou: 0.6988 - recall_4: 0.8407 - precision_4: 0.9163 - val_loss: 0.8726 - val_dice_coef: 0.6110 - val_iou: 0.4477 - val_recall_4: 0.7802 - val_precision_4: 0.5490 - lr: 1.0000e-04\n",
            "Epoch 19/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2656 - dice_coef: 0.8389 - iou: 0.7243 - recall_4: 0.8535 - precision_4: 0.9305\n",
            "Epoch 19: val_loss did not improve from 0.74778\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "98/98 [==============================] - 13s 138ms/step - loss: 0.2656 - dice_coef: 0.8389 - iou: 0.7243 - recall_4: 0.8535 - precision_4: 0.9305 - val_loss: 0.7582 - val_dice_coef: 0.6369 - val_iou: 0.4745 - val_recall_4: 0.7203 - val_precision_4: 0.6227 - lr: 1.0000e-04\n",
            "Epoch 20/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2575 - dice_coef: 0.8444 - iou: 0.7330 - recall_4: 0.8688 - precision_4: 0.9222\n",
            "Epoch 20: val_loss improved from 0.74778 to 0.73760, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 143ms/step - loss: 0.2575 - dice_coef: 0.8444 - iou: 0.7330 - recall_4: 0.8688 - precision_4: 0.9222 - val_loss: 0.7376 - val_dice_coef: 0.6441 - val_iou: 0.4806 - val_recall_4: 0.7167 - val_precision_4: 0.6399 - lr: 1.0000e-05\n",
            "Epoch 21/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2424 - dice_coef: 0.8522 - iou: 0.7442 - recall_4: 0.8654 - precision_4: 0.9403\n",
            "Epoch 21: val_loss improved from 0.73760 to 0.72647, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 147ms/step - loss: 0.2424 - dice_coef: 0.8522 - iou: 0.7442 - recall_4: 0.8654 - precision_4: 0.9403 - val_loss: 0.7265 - val_dice_coef: 0.6482 - val_iou: 0.4850 - val_recall_4: 0.7232 - val_precision_4: 0.6440 - lr: 1.0000e-05\n",
            "Epoch 22/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2378 - dice_coef: 0.8549 - iou: 0.7483 - recall_4: 0.8678 - precision_4: 0.9427\n",
            "Epoch 22: val_loss improved from 0.72647 to 0.70876, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 140ms/step - loss: 0.2378 - dice_coef: 0.8549 - iou: 0.7483 - recall_4: 0.8678 - precision_4: 0.9427 - val_loss: 0.7088 - val_dice_coef: 0.6546 - val_iou: 0.4925 - val_recall_4: 0.7258 - val_precision_4: 0.6540 - lr: 1.0000e-05\n",
            "Epoch 23/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2342 - dice_coef: 0.8570 - iou: 0.7514 - recall_4: 0.8697 - precision_4: 0.9443\n",
            "Epoch 23: val_loss improved from 0.70876 to 0.69980, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 140ms/step - loss: 0.2342 - dice_coef: 0.8570 - iou: 0.7514 - recall_4: 0.8697 - precision_4: 0.9443 - val_loss: 0.6998 - val_dice_coef: 0.6593 - val_iou: 0.4983 - val_recall_4: 0.7310 - val_precision_4: 0.6581 - lr: 1.0000e-05\n",
            "Epoch 24/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2312 - dice_coef: 0.8589 - iou: 0.7542 - recall_4: 0.8712 - precision_4: 0.9456\n",
            "Epoch 24: val_loss improved from 0.69980 to 0.68398, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 142ms/step - loss: 0.2312 - dice_coef: 0.8589 - iou: 0.7542 - recall_4: 0.8712 - precision_4: 0.9456 - val_loss: 0.6840 - val_dice_coef: 0.6651 - val_iou: 0.5054 - val_recall_4: 0.7292 - val_precision_4: 0.6698 - lr: 1.0000e-05\n",
            "Epoch 25/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2285 - dice_coef: 0.8606 - iou: 0.7568 - recall_4: 0.8726 - precision_4: 0.9468\n",
            "Epoch 25: val_loss improved from 0.68398 to 0.66791, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 13s 138ms/step - loss: 0.2285 - dice_coef: 0.8606 - iou: 0.7568 - recall_4: 0.8726 - precision_4: 0.9468 - val_loss: 0.6679 - val_dice_coef: 0.6708 - val_iou: 0.5121 - val_recall_4: 0.7249 - val_precision_4: 0.6834 - lr: 1.0000e-05\n",
            "Epoch 26/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2259 - dice_coef: 0.8622 - iou: 0.7593 - recall_4: 0.8739 - precision_4: 0.9478\n",
            "Epoch 26: val_loss improved from 0.66791 to 0.65225, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 139ms/step - loss: 0.2259 - dice_coef: 0.8622 - iou: 0.7593 - recall_4: 0.8739 - precision_4: 0.9478 - val_loss: 0.6522 - val_dice_coef: 0.6763 - val_iou: 0.5185 - val_recall_4: 0.7200 - val_precision_4: 0.6973 - lr: 1.0000e-05\n",
            "Epoch 27/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2234 - dice_coef: 0.8637 - iou: 0.7616 - recall_4: 0.8751 - precision_4: 0.9488\n",
            "Epoch 27: val_loss improved from 0.65225 to 0.63891, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 139ms/step - loss: 0.2234 - dice_coef: 0.8637 - iou: 0.7616 - recall_4: 0.8751 - precision_4: 0.9488 - val_loss: 0.6389 - val_dice_coef: 0.6810 - val_iou: 0.5241 - val_recall_4: 0.7147 - val_precision_4: 0.7101 - lr: 1.0000e-05\n",
            "Epoch 28/200\n",
            "97/98 [============================>.] - ETA: 0s - loss: 0.2214 - dice_coef: 0.8650 - iou: 0.7636 - recall_4: 0.8761 - precision_4: 0.9496\n",
            "Epoch 28: val_loss improved from 0.63891 to 0.62785, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 143ms/step - loss: 0.2211 - dice_coef: 0.8652 - iou: 0.7639 - recall_4: 0.8762 - precision_4: 0.9497 - val_loss: 0.6278 - val_dice_coef: 0.6851 - val_iou: 0.5290 - val_recall_4: 0.7096 - val_precision_4: 0.7219 - lr: 1.0000e-05\n",
            "Epoch 29/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2188 - dice_coef: 0.8667 - iou: 0.7662 - recall_4: 0.8773 - precision_4: 0.9506\n",
            "Epoch 29: val_loss improved from 0.62785 to 0.61895, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 13s 137ms/step - loss: 0.2188 - dice_coef: 0.8667 - iou: 0.7662 - recall_4: 0.8773 - precision_4: 0.9506 - val_loss: 0.6190 - val_dice_coef: 0.6886 - val_iou: 0.5332 - val_recall_4: 0.7051 - val_precision_4: 0.7325 - lr: 1.0000e-05\n",
            "Epoch 30/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2165 - dice_coef: 0.8681 - iou: 0.7684 - recall_4: 0.8783 - precision_4: 0.9515\n",
            "Epoch 30: val_loss improved from 0.61895 to 0.61197, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 139ms/step - loss: 0.2165 - dice_coef: 0.8681 - iou: 0.7684 - recall_4: 0.8783 - precision_4: 0.9515 - val_loss: 0.6120 - val_dice_coef: 0.6913 - val_iou: 0.5366 - val_recall_4: 0.7005 - val_precision_4: 0.7416 - lr: 1.0000e-05\n",
            "Epoch 31/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2144 - dice_coef: 0.8695 - iou: 0.7705 - recall_4: 0.8793 - precision_4: 0.9523\n",
            "Epoch 31: val_loss improved from 0.61197 to 0.60617, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 142ms/step - loss: 0.2144 - dice_coef: 0.8695 - iou: 0.7705 - recall_4: 0.8793 - precision_4: 0.9523 - val_loss: 0.6062 - val_dice_coef: 0.6936 - val_iou: 0.5395 - val_recall_4: 0.6956 - val_precision_4: 0.7504 - lr: 1.0000e-05\n",
            "Epoch 32/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2122 - dice_coef: 0.8709 - iou: 0.7727 - recall_4: 0.8803 - precision_4: 0.9531\n",
            "Epoch 32: val_loss improved from 0.60617 to 0.60190, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 13s 132ms/step - loss: 0.2122 - dice_coef: 0.8709 - iou: 0.7727 - recall_4: 0.8803 - precision_4: 0.9531 - val_loss: 0.6019 - val_dice_coef: 0.6954 - val_iou: 0.5419 - val_recall_4: 0.6909 - val_precision_4: 0.7584 - lr: 1.0000e-05\n",
            "Epoch 33/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2101 - dice_coef: 0.8723 - iou: 0.7748 - recall_4: 0.8812 - precision_4: 0.9539\n",
            "Epoch 33: val_loss improved from 0.60190 to 0.59895, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 141ms/step - loss: 0.2101 - dice_coef: 0.8723 - iou: 0.7748 - recall_4: 0.8812 - precision_4: 0.9539 - val_loss: 0.5990 - val_dice_coef: 0.6969 - val_iou: 0.5438 - val_recall_4: 0.6866 - val_precision_4: 0.7651 - lr: 1.0000e-05\n",
            "Epoch 34/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2080 - dice_coef: 0.8736 - iou: 0.7769 - recall_4: 0.8822 - precision_4: 0.9546\n",
            "Epoch 34: val_loss improved from 0.59895 to 0.59679, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 15s 151ms/step - loss: 0.2080 - dice_coef: 0.8736 - iou: 0.7769 - recall_4: 0.8822 - precision_4: 0.9546 - val_loss: 0.5968 - val_dice_coef: 0.6980 - val_iou: 0.5453 - val_recall_4: 0.6823 - val_precision_4: 0.7714 - lr: 1.0000e-05\n",
            "Epoch 35/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2060 - dice_coef: 0.8750 - iou: 0.7790 - recall_4: 0.8831 - precision_4: 0.9553\n",
            "Epoch 35: val_loss improved from 0.59679 to 0.59562, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 13s 138ms/step - loss: 0.2060 - dice_coef: 0.8750 - iou: 0.7790 - recall_4: 0.8831 - precision_4: 0.9553 - val_loss: 0.5956 - val_dice_coef: 0.6988 - val_iou: 0.5464 - val_recall_4: 0.6786 - val_precision_4: 0.7764 - lr: 1.0000e-05\n",
            "Epoch 36/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2040 - dice_coef: 0.8763 - iou: 0.7810 - recall_4: 0.8840 - precision_4: 0.9560\n",
            "Epoch 36: val_loss improved from 0.59562 to 0.59504, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 11s 115ms/step - loss: 0.2040 - dice_coef: 0.8763 - iou: 0.7810 - recall_4: 0.8840 - precision_4: 0.9560 - val_loss: 0.5950 - val_dice_coef: 0.6992 - val_iou: 0.5472 - val_recall_4: 0.6745 - val_precision_4: 0.7810 - lr: 1.0000e-05\n",
            "Epoch 37/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2020 - dice_coef: 0.8776 - iou: 0.7831 - recall_4: 0.8849 - precision_4: 0.9567\n",
            "Epoch 37: val_loss improved from 0.59504 to 0.59499, saving model to files/NanoNet_A/model.h5\n",
            "98/98 [==============================] - 14s 144ms/step - loss: 0.2020 - dice_coef: 0.8776 - iou: 0.7831 - recall_4: 0.8849 - precision_4: 0.9567 - val_loss: 0.5950 - val_dice_coef: 0.6994 - val_iou: 0.5475 - val_recall_4: 0.6709 - val_precision_4: 0.7845 - lr: 1.0000e-05\n",
            "Epoch 38/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.2000 - dice_coef: 0.8789 - iou: 0.7851 - recall_4: 0.8857 - precision_4: 0.9574\n",
            "Epoch 38: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 128ms/step - loss: 0.2000 - dice_coef: 0.8789 - iou: 0.7851 - recall_4: 0.8857 - precision_4: 0.9574 - val_loss: 0.5954 - val_dice_coef: 0.6994 - val_iou: 0.5476 - val_recall_4: 0.6674 - val_precision_4: 0.7875 - lr: 1.0000e-05\n",
            "Epoch 39/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1980 - dice_coef: 0.8802 - iou: 0.7871 - recall_4: 0.8865 - precision_4: 0.9580\n",
            "Epoch 39: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 14s 142ms/step - loss: 0.1980 - dice_coef: 0.8802 - iou: 0.7871 - recall_4: 0.8865 - precision_4: 0.9580 - val_loss: 0.5959 - val_dice_coef: 0.6993 - val_iou: 0.5477 - val_recall_4: 0.6639 - val_precision_4: 0.7905 - lr: 1.0000e-05\n",
            "Epoch 40/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1961 - dice_coef: 0.8814 - iou: 0.7891 - recall_4: 0.8874 - precision_4: 0.9586\n",
            "Epoch 40: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 14s 139ms/step - loss: 0.1961 - dice_coef: 0.8814 - iou: 0.7891 - recall_4: 0.8874 - precision_4: 0.9586 - val_loss: 0.5965 - val_dice_coef: 0.6993 - val_iou: 0.5478 - val_recall_4: 0.6613 - val_precision_4: 0.7928 - lr: 1.0000e-05\n",
            "Epoch 41/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1942 - dice_coef: 0.8827 - iou: 0.7911 - recall_4: 0.8881 - precision_4: 0.9592\n",
            "Epoch 41: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 137ms/step - loss: 0.1942 - dice_coef: 0.8827 - iou: 0.7911 - recall_4: 0.8881 - precision_4: 0.9592 - val_loss: 0.5972 - val_dice_coef: 0.6992 - val_iou: 0.5477 - val_recall_4: 0.6584 - val_precision_4: 0.7950 - lr: 1.0000e-05\n",
            "Epoch 42/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1923 - dice_coef: 0.8839 - iou: 0.7930 - recall_4: 0.8889 - precision_4: 0.9598\n",
            "Epoch 42: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 133ms/step - loss: 0.1923 - dice_coef: 0.8839 - iou: 0.7930 - recall_4: 0.8889 - precision_4: 0.9598 - val_loss: 0.5980 - val_dice_coef: 0.6992 - val_iou: 0.5478 - val_recall_4: 0.6568 - val_precision_4: 0.7964 - lr: 1.0000e-05\n",
            "Epoch 43/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1904 - dice_coef: 0.8851 - iou: 0.7950 - recall_4: 0.8897 - precision_4: 0.9604\n",
            "Epoch 43: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 14s 141ms/step - loss: 0.1904 - dice_coef: 0.8851 - iou: 0.7950 - recall_4: 0.8897 - precision_4: 0.9604 - val_loss: 0.5988 - val_dice_coef: 0.6991 - val_iou: 0.5477 - val_recall_4: 0.6546 - val_precision_4: 0.7981 - lr: 1.0000e-05\n",
            "Epoch 44/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1886 - dice_coef: 0.8863 - iou: 0.7969 - recall_4: 0.8905 - precision_4: 0.9610\n",
            "Epoch 44: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 135ms/step - loss: 0.1886 - dice_coef: 0.8863 - iou: 0.7969 - recall_4: 0.8905 - precision_4: 0.9610 - val_loss: 0.5999 - val_dice_coef: 0.6989 - val_iou: 0.5476 - val_recall_4: 0.6530 - val_precision_4: 0.7990 - lr: 1.0000e-05\n",
            "Epoch 45/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1867 - dice_coef: 0.8875 - iou: 0.7988 - recall_4: 0.8912 - precision_4: 0.9615\n",
            "Epoch 45: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 137ms/step - loss: 0.1867 - dice_coef: 0.8875 - iou: 0.7988 - recall_4: 0.8912 - precision_4: 0.9615 - val_loss: 0.6009 - val_dice_coef: 0.6988 - val_iou: 0.5476 - val_recall_4: 0.6517 - val_precision_4: 0.7998 - lr: 1.0000e-05\n",
            "Epoch 46/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1849 - dice_coef: 0.8887 - iou: 0.8007 - recall_4: 0.8919 - precision_4: 0.9621\n",
            "Epoch 46: val_loss did not improve from 0.59499\n",
            "\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "98/98 [==============================] - 13s 133ms/step - loss: 0.1849 - dice_coef: 0.8887 - iou: 0.8007 - recall_4: 0.8919 - precision_4: 0.9621 - val_loss: 0.6019 - val_dice_coef: 0.6987 - val_iou: 0.5475 - val_recall_4: 0.6504 - val_precision_4: 0.8005 - lr: 1.0000e-05\n",
            "Epoch 47/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1827 - dice_coef: 0.8900 - iou: 0.8028 - recall_4: 0.8971 - precision_4: 0.9596\n",
            "Epoch 47: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 16s 167ms/step - loss: 0.1827 - dice_coef: 0.8900 - iou: 0.8028 - recall_4: 0.8971 - precision_4: 0.9596 - val_loss: 0.6058 - val_dice_coef: 0.7011 - val_iou: 0.5502 - val_recall_4: 0.6741 - val_precision_4: 0.7771 - lr: 1.0000e-06\n",
            "Epoch 48/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1815 - dice_coef: 0.8906 - iou: 0.8038 - recall_4: 0.8953 - precision_4: 0.9620\n",
            "Epoch 48: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 11s 113ms/step - loss: 0.1815 - dice_coef: 0.8906 - iou: 0.8038 - recall_4: 0.8953 - precision_4: 0.9620 - val_loss: 0.6083 - val_dice_coef: 0.7007 - val_iou: 0.5497 - val_recall_4: 0.6781 - val_precision_4: 0.7721 - lr: 1.0000e-06\n",
            "Epoch 49/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1811 - dice_coef: 0.8908 - iou: 0.8041 - recall_4: 0.8947 - precision_4: 0.9628\n",
            "Epoch 49: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 15s 154ms/step - loss: 0.1811 - dice_coef: 0.8908 - iou: 0.8041 - recall_4: 0.8947 - precision_4: 0.9628 - val_loss: 0.6089 - val_dice_coef: 0.7004 - val_iou: 0.5493 - val_recall_4: 0.6776 - val_precision_4: 0.7721 - lr: 1.0000e-06\n",
            "Epoch 50/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1808 - dice_coef: 0.8910 - iou: 0.8043 - recall_4: 0.8945 - precision_4: 0.9631\n",
            "Epoch 50: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 12s 126ms/step - loss: 0.1808 - dice_coef: 0.8910 - iou: 0.8043 - recall_4: 0.8945 - precision_4: 0.9631 - val_loss: 0.6090 - val_dice_coef: 0.7002 - val_iou: 0.5491 - val_recall_4: 0.6764 - val_precision_4: 0.7731 - lr: 1.0000e-06\n",
            "Epoch 51/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1806 - dice_coef: 0.8911 - iou: 0.8046 - recall_4: 0.8944 - precision_4: 0.9633\n",
            "Epoch 51: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 134ms/step - loss: 0.1806 - dice_coef: 0.8911 - iou: 0.8046 - recall_4: 0.8944 - precision_4: 0.9633 - val_loss: 0.6090 - val_dice_coef: 0.7001 - val_iou: 0.5489 - val_recall_4: 0.6753 - val_precision_4: 0.7742 - lr: 1.0000e-06\n",
            "Epoch 52/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1804 - dice_coef: 0.8912 - iou: 0.8048 - recall_4: 0.8944 - precision_4: 0.9634\n",
            "Epoch 52: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 133ms/step - loss: 0.1804 - dice_coef: 0.8912 - iou: 0.8048 - recall_4: 0.8944 - precision_4: 0.9634 - val_loss: 0.6091 - val_dice_coef: 0.6999 - val_iou: 0.5488 - val_recall_4: 0.6744 - val_precision_4: 0.7749 - lr: 1.0000e-06\n",
            "Epoch 53/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1802 - dice_coef: 0.8914 - iou: 0.8050 - recall_4: 0.8945 - precision_4: 0.9635\n",
            "Epoch 53: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 136ms/step - loss: 0.1802 - dice_coef: 0.8914 - iou: 0.8050 - recall_4: 0.8945 - precision_4: 0.9635 - val_loss: 0.6091 - val_dice_coef: 0.6998 - val_iou: 0.5487 - val_recall_4: 0.6736 - val_precision_4: 0.7755 - lr: 1.0000e-06\n",
            "Epoch 54/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1800 - dice_coef: 0.8915 - iou: 0.8052 - recall_4: 0.8945 - precision_4: 0.9636\n",
            "Epoch 54: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 138ms/step - loss: 0.1800 - dice_coef: 0.8915 - iou: 0.8052 - recall_4: 0.8945 - precision_4: 0.9636 - val_loss: 0.6092 - val_dice_coef: 0.6998 - val_iou: 0.5486 - val_recall_4: 0.6732 - val_precision_4: 0.7758 - lr: 1.0000e-06\n",
            "Epoch 55/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1798 - dice_coef: 0.8916 - iou: 0.8054 - recall_4: 0.8946 - precision_4: 0.9637\n",
            "Epoch 55: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 136ms/step - loss: 0.1798 - dice_coef: 0.8916 - iou: 0.8054 - recall_4: 0.8946 - precision_4: 0.9637 - val_loss: 0.6093 - val_dice_coef: 0.6997 - val_iou: 0.5485 - val_recall_4: 0.6729 - val_precision_4: 0.7760 - lr: 1.0000e-06\n",
            "Epoch 56/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1796 - dice_coef: 0.8918 - iou: 0.8056 - recall_4: 0.8946 - precision_4: 0.9637\n",
            "Epoch 56: val_loss did not improve from 0.59499\n",
            "\n",
            "Epoch 56: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "98/98 [==============================] - 14s 141ms/step - loss: 0.1796 - dice_coef: 0.8918 - iou: 0.8056 - recall_4: 0.8946 - precision_4: 0.9637 - val_loss: 0.6094 - val_dice_coef: 0.6997 - val_iou: 0.5485 - val_recall_4: 0.6726 - val_precision_4: 0.7762 - lr: 1.0000e-06\n",
            "Epoch 57/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 0.1791 - dice_coef: 0.8920 - iou: 0.8061 - recall_4: 0.8947 - precision_4: 0.9640\n",
            "Epoch 57: val_loss did not improve from 0.59499\n",
            "98/98 [==============================] - 13s 135ms/step - loss: 0.1791 - dice_coef: 0.8920 - iou: 0.8061 - recall_4: 0.8947 - precision_4: 0.9640 - val_loss: 0.6104 - val_dice_coef: 0.6998 - val_iou: 0.5486 - val_recall_4: 0.6754 - val_precision_4: 0.7734 - lr: 1.0000e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "G0qoXyNT9zJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import time\n",
        "from operator import add\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import (\n",
        "    jaccard_score, f1_score, recall_score, precision_score, accuracy_score, fbeta_score)\n",
        "\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    y_pred = y_pred > 0.5\n",
        "    y_pred = y_pred.reshape(-1)\n",
        "    y_pred = y_pred.astype(np.uint8)\n",
        "\n",
        "    y_true = y_true > 0.5\n",
        "    y_true = y_true.reshape(-1)\n",
        "    y_true = y_true.astype(np.uint8)\n",
        "\n",
        "    ## Score\n",
        "    score_jaccard = jaccard_score(y_true, y_pred, average='binary')\n",
        "    score_f1 = f1_score(y_true, y_pred, average='binary')\n",
        "    score_recall = recall_score(y_true, y_pred, average='binary')\n",
        "    score_precision = precision_score(y_true, y_pred, average='binary', zero_division=1)\n",
        "    score_acc = accuracy_score(y_true, y_pred)\n",
        "    score_fbeta = fbeta_score(y_true, y_pred, beta=2.0, average='binary', zero_division=1)\n",
        "\n",
        "    return [score_jaccard, score_f1, score_recall, score_precision, score_acc, score_fbeta]\n",
        "\n",
        "def mask_parse(mask):\n",
        "    mask = np.squeeze(mask)\n",
        "    mask = [mask, mask, mask]\n",
        "    mask = np.transpose(mask, (1, 2, 0))\n",
        "    return mask\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Load dataset \"\"\"\n",
        "    path = \"/content/drive/MyDrive/capstone/Kvasir-SEG\"\n",
        "    (train_x, train_y), (test_x, test_y) = load_test_data(path)\n",
        "\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    size = (256, 256)\n",
        "    input_shape = (256, 256, 3)\n",
        "    model_name = \"NanoNet_A\"\n",
        "    model_path = f\"files/{model_name}/model.h5\"\n",
        "\n",
        "    \"\"\" Directories \"\"\"\n",
        "    create_dir(f\"results/{model_name}\")\n",
        "\n",
        "    \"\"\" Load the model \"\"\"\n",
        "    model = load_model_file(model_path)\n",
        "\n",
        "    \"\"\" Sample prediction: To improve FPS \"\"\"\n",
        "    image = np.zeros((1, 256, 256, 3))\n",
        "    mask = model.predict(image)\n",
        "\n",
        "    \"\"\" Testing \"\"\"\n",
        "    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "    time_taken = []\n",
        "\n",
        "    for i, (x, y) in enumerate(zip(test_x, test_y)):\n",
        "        name = y.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "        \"\"\" Image \"\"\"\n",
        "        image = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "        image = cv2.resize(image, size)\n",
        "        ori_img = image\n",
        "        image = image/255.0\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "        image = image.astype(np.float32)\n",
        "\n",
        "        \"\"\" Mask \"\"\"\n",
        "        mask = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.resize(mask, size)\n",
        "        ori_mask = mask\n",
        "        mask = np.expand_dims(mask, axis=0)\n",
        "        mask = mask/255.0\n",
        "        mask = mask.astype(np.float32)\n",
        "\n",
        "        \"\"\" Time taken \"\"\"\n",
        "        start_time = time.time()\n",
        "        pred_y = model.predict(image)\n",
        "        total_time = time.time() - start_time\n",
        "        time_taken.append(total_time)\n",
        "        print(f\"{name}: {total_time:1.5f}\")\n",
        "\n",
        "        \"\"\" Metrics calculation \"\"\"\n",
        "        score = calculate_metrics(mask, pred_y)\n",
        "        metrics_score = list(map(add, metrics_score, score))\n",
        "\n",
        "        \"\"\" Saving masks \"\"\"\n",
        "        pred_y = pred_y[0] > 0.5\n",
        "        pred_y = pred_y * 255\n",
        "        pred_y = np.array(pred_y, dtype=np.uint8)\n",
        "\n",
        "        ori_img = ori_img\n",
        "        ori_mask = mask_parse(ori_mask)\n",
        "        pred_y = mask_parse(pred_y)\n",
        "        sep_line = np.ones((size[0], 10, 3)) * 255\n",
        "\n",
        "        tmp = [\n",
        "            ori_img, sep_line,\n",
        "            ori_mask, sep_line,\n",
        "            pred_y\n",
        "        ]\n",
        "\n",
        "        cat_images = np.concatenate(tmp, axis=1)\n",
        "        cv2.imwrite(f\"results/{model_name}/{name}.png\", cat_images)\n",
        "\n",
        "    jaccard = metrics_score[0]/len(test_x)\n",
        "    f1 = metrics_score[1]/len(test_x)\n",
        "    recall = metrics_score[2]/len(test_x)\n",
        "    precision = metrics_score[3]/len(test_x)\n",
        "    acc = metrics_score[4]/len(test_x)\n",
        "    f2 = metrics_score[5]/len(test_x)\n",
        "\n",
        "    print(\"\")\n",
        "    print(f\"Jaccard: {jaccard:1.4f} - F1: {f1:1.4f} - Recall: {recall:1.4f} - Precision: {precision:1.4f} - Acc: {acc:1.4f} - F2: {f2:1.4f}\")\n",
        "\n",
        "    mean_time_taken = np.mean(time_taken)\n",
        "    mean_fps = 1/mean_time_taken\n",
        "    print(\"Mean FPS: \", mean_fps)"
      ],
      "metadata": {
        "id": "fJg8vXU79w8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3febd4e5-fc92-423b-bd19-f8de8f379d4c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "cju87vqa0ndwg0850onjdz7ol: 0.11336\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "cju87xn2snfmv0987sc3d9xnq: 0.09911\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "cju87z6o6nh73085045bzsx6o: 0.11243\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "cju87zv8lni0o0850hbbecbq6: 0.10347\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "cju8828oxnool0801qno9luhr: 0.15811\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "cju884985nlmx0817vzpax3y4: 0.10080\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "cju7dp3dw2k4n0755zhe003ad: 0.07886\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju7dqcwi2dz00850gcmr2ert: 0.06914\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju7druhp2gp308715i6km7be: 0.07453\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju7dsrtb2f8i085064kwugfk: 0.07667\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju7dtb1e2j0t0818deq51ib3: 0.07085\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju7dubap2g0w0801fgl42mg9: 0.07399\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju7dvl5m2n4t0755hlnnjjet: 0.07987\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju7dwe282dc309876rco45ts: 0.07344\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju7dxffn2eam0817qxosfwch: 0.07346\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju7dymur2od30755eg8yv2ht: 0.07588\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju7dz5yy2i7z0801ausi7rna: 0.07445\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju7ea4om2l910801bohqjccy: 0.07070\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju7ebe962hr409872ovibahw: 0.07387\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "cju7ecl9i2i060987xawjp4l0: 0.07686\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju7eea9b2m0z0801ynqv1fqu: 0.07778\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju88oh0po9gq0801nge4tgr1: 0.07324\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "cju88q6h6obpd0871ckmiabbo: 0.07237\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "cju88rl5eo94l0850kf5wtrm1: 0.07234\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju88t4fvokxf07558ymyh281: 0.07137\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju88trl3ogi208716qvti51b: 0.08185\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "cju88v2f9oi8w0871hx9auh01: 0.07647\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "cju88vx2uoocy075531lc63n3: 0.07150\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju88y1mwoln50871emyfny1g: 0.07916\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju88z8bson4h0871nnd7fdxo: 0.07236\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju890guyoiti098753yg6cdu: 0.07018\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "cju8914beokbf0850isxpocrk: 0.07160\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "cju892fesoq2g0801n0e0jyia: 0.07292\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju893jmdompz0817xn3g1w4h: 0.08086\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju89y9h0puti0818i5yw29e6: 0.08274\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju89z6pqpqfx0817mfv8ixjc: 0.07106\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8a1jtvpt9m081712iwkca7: 0.07545\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8a2itsq4dv0755ntlovpxe: 0.06966\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8a3nhbpwnb0850d37fo2na: 0.07670\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8a56vxpy780850r45yu4wk: 0.07591\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju8a84g0q76m0818hwiggkod: 0.08255\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8abobpqbir08189u01huru: 0.06820\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju8adb60qbiu080188mxpf8d: 0.06907\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju8aeei7q8k308173n9y4klv: 0.07635\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8aj01yqeqm0850lhdz3xdw: 0.08703\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8alhigqn2h0801zksudldd: 0.07317\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8amfdtqi4x09871tygrgqe: 0.07804\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "cju8ando2qqdo0818ck7i1be1: 0.07093\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju8apjewqrk00801k5d71gky: 0.07322\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju8aqq8uqmoq0987hphto9gg: 0.07118\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju8arof2qpf20850ifr1bnqj: 0.07471\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8ashhnquqr0801rwduzt7d: 0.06917\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju8at3s1qqqx0850hcq8nmnq: 0.08094\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8auylgqx0z0871u4o4db7o: 0.08225\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8aw9n1qyg10801jkjlmors: 0.07904\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju8axq24r4an0755yhv9d4ly: 0.07197\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju8ayeq7r1fb0818z1junacy: 0.07451\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "cju8azmhcr66e0755t61atz72: 0.07009\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8b0jr0r2oi0801jiquetd5: 0.07127\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8b1v3br45u087189kku66u: 0.07685\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju8b2rmgr52s0801p54eyflx: 0.07337\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "cju8b3ka8r64u0801fh18hk7l: 0.07839\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "cju8b4ja9r2s808509d45ma86: 0.09660\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "cju8b542nr81x0871uxnkm9ih: 0.09740\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "cju8b5p40r2c60987ofa0mu03: 0.09296\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "cju8b6rp0r5st0850184f79xt: 0.14096\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "cju8b7aqtr4a00987coba14b7: 0.11335\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "cju8b8yair65w09878pyqtr96: 0.11669\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "cju8bafgqrf4x0818twisk3ea: 0.10936\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "cju8bbznkrf5g0871jncffynk: 0.10921\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "cju8bff9nrfi10850fmfzbf8v: 0.11211\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "cju8bgdmqrksy0801tozdmraa: 0.10711\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "cju8bh8surexp0987o5pzklk1: 0.13940\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "cju8bi8q7rlmn0871abc5ch8k: 0.13480\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "cju8bj2ssrmlm0871gc2ug2rs: 0.10895\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "cju8bk8oirjhw0817hgkua2w8: 0.10697\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "cju8bljw9rqk20801kr54akrl: 0.11800\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "cju8bm24yrrdp081829mbo8ic: 0.11893\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8bn7m2rmm70817hgxpb1uq: 0.07468\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "cju8bop5jrsid08716i24fqda: 0.07423\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8bpctzrqkr0850zeldv9kt: 0.07949\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju8bqxxurs6i0850mu7mtef9: 0.07271\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "cju8brv16rx7f0818uf5n89pv: 0.07917\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8bssulrrcy0987h1vq5060: 0.07477\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8buos5rz9b08715lfr0f4f: 0.07953\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju8bw697rwg308177tg8huas: 0.07932\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju8bysfgrzkl081786jwac09: 0.07862\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8bzzy2s66m08016z6mouqt: 0.07816\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "cju8c1a0ws7o208181c6lbsom: 0.07988\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8c2rqzs5t80850d0zky5dy: 0.07605\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju8c3xs7sauj0801ieyzezr5: 0.07809\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju8c5223s8j80850b4kealt4: 0.07231\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8c5mxls96t0850wvkvsity: 0.07737\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8c5zcbsdfz0801o5t6jag1: 0.07206\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "cju8c6hnxsdvr0801wn0vrsa6: 0.07917\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8c82iosagu0817l74s4m5g: 0.07686\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju8c9akjsdjj0850s67uzlxq: 0.07928\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju8ca4geseia0850i2ru11hw: 0.07989\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju8cattbsivm0818p446wgel: 0.07576\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "cju8cbsyssiqj0871gr4jedjp: 0.08025\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju7efffp2ivf0817etg3jehl: 0.07388\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "cju6x35ervu2808015c7eoqe4: 0.07734\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju6x4t13vyw60755gtcf9ndu: 0.07932\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju6x97w4vwua0850x0997r0a: 0.07951\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju6xa0qmvzun0818xjukgncj: 0.07455\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju6xifswvwbo0987nibtdr50: 0.08659\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju6xlygpw7bs0818n691jsq4: 0.07625\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "cju6xmqd9w0250817l5kxfnsk: 0.07904\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "cju6ywm40wdbo0987pbftsvtg: 0.07248\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "cju6yxyt0wh080871sqpepu47: 0.07223\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju6yywx1whbb0871ksgfgf9f: 0.07382\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "cju6z1bzbwfq50817b2alatvr: 0.07715\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "cju6z2616wqbk07555bvnuyr1: 0.07508\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju6z600qwh4z081700qimgl9: 0.07481\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju6z7e4bwgdd0987ogkzq9kt: 0.07265\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "cju6z9a9kwsl007552s49rx6i: 0.07018\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "cju76erapykj30871x5eaxh4q: 0.07409\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "cju76l27oyrw907551ri2a7fl: 0.06899\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "cju76lsehyia10987u54vn8rb: 0.08117\n",
            "\n",
            "Jaccard: 0.6510 - F1: 0.7604 - Recall: 0.7744 - Precision: 0.8264 - Acc: 0.9338 - F2: 0.7599\n",
            "Mean FPS:  12.096922997986999\n"
          ]
        }
      ]
    }
  ]
}